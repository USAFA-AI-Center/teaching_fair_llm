{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Advanced Agentic AI\n",
    "\n",
    "## Grounding Foundation Models & Multi-Agent Committees\n",
    "\n",
    "In Lesson 1, you learned that LLMs are powerful pattern predictors but have limitations:\n",
    "- They can't access real-time information\n",
    "- They don't know about YOUR specific data\n",
    "- They work in isolation\n",
    "\n",
    "Today, we'll solve these problems by:\n",
    "1. **Grounding** LLMs with your own knowledge base\n",
    "2. **Coordinating** multiple agents to solve complex tasks\n",
    "\n",
    "# **Guiding Questions:**\n",
    "1. How can we make LLMs answer questions about information they've never seen?\n",
    "2. Can multiple AI agents work together better than one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Grounding Foundation Models\n",
    "\n",
    "## What Does \"Grounding\" Mean?\n",
    "\n",
    "**Grounding** means connecting an LLM's responses to specific, verifiable sources of information.\n",
    "\n",
    "### The Problem:\n",
    "- LLMs only know what was in their training data (cutoff: early 2024 for most models)\n",
    "- They hallucinate when they don't know something\n",
    "- They can't access YOUR documents, databases, or private information\n",
    "\n",
    "### The Solution: RAG (Retrieval-Augmented Generation)\n",
    "**RAG** = Retrieve relevant information → Augment the prompt → Generate grounded responses\n",
    "\n",
    "Think of it like an open-book exam vs. a closed-book exam!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries\n",
    "\n",
    "Let's set up our environment for building a grounded agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from fairlib.modules.mal.huggingface_adapter import HuggingFaceAdapter\n",
    "from fairlib.core.message import Message\n",
    "from fairlib.core.tool import BaseTool, ToolRegistry\n",
    "from fairlib.core.tool_executor import ToolExecutor\n",
    "from fairlib.core.memory import WorkingMemory\n",
    "from fairlib.prompting.role_definition import RoleDefinition\n",
    "from fairlib.agents.simple_agent import SimpleAgent\n",
    "from fairlib.planning.simple_react_planner import SimpleReActPlanner\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "\n",
    "if not token:\n",
    "    print(\"Warning: HUGGING_FACE_HUB_TOKEN not found in .env file!\")\n",
    "else:\n",
    "    print(\"Token loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: The Hallucination Problem\n",
    "\n",
    "Let's see what happens when we ask an LLM about information it doesn't have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a language model\n",
    "print(\"Loading language model...\")\n",
    "llm = HuggingFaceAdapter(model_name=\"dolphin3-qwen25-3b\", auth_token=token)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about fictional company policy\n",
    "question = \"What is Acme Corporation's policy on remote work?\"\n",
    "\n",
    "messages = [Message(role=\"user\", content=question)]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nLLM Response:\\n{response.content}\")\n",
    "print(\"\\n⚠️ WARNING: This information might be completely made up! ⚠️\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection Question 1\n",
    "\n",
    "**Did the LLM admit it doesn't know, or did it make something up?**\n",
    "\n",
    "This is the hallucination problem: LLMs try to answer even when they don't have the information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Knowledge Base\n",
    "\n",
    "Let's create a simple document store that represents company knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake knowledge base (in real systems, this would be a vector database)\n",
    "KNOWLEDGE_BASE = {\n",
    "    \"remote_work\": \"\"\"\n",
    "    Acme Corporation Remote Work Policy (Updated 2024):\n",
    "    \n",
    "    - All employees may work remotely up to 3 days per week\n",
    "    - Managers must approve remote schedules in advance\n",
    "    - Core collaboration hours are 10 AM - 3 PM EST\n",
    "    - Video must be enabled during team meetings\n",
    "    - Home office equipment reimbursement: up to $500/year\n",
    "    \"\"\",\n",
    "    \n",
    "    \"vacation\": \"\"\"\n",
    "    Acme Corporation Vacation Policy:\n",
    "    \n",
    "    - New employees: 15 days PTO per year\n",
    "    - After 3 years: 20 days PTO per year\n",
    "    - After 7 years: 25 days PTO per year\n",
    "    - Vacation requests must be submitted 2 weeks in advance\n",
    "    - Maximum carryover: 5 unused days to next year\n",
    "    \"\"\",\n",
    "    \n",
    "    \"benefits\": \"\"\"\n",
    "    Acme Corporation Benefits Package:\n",
    "    \n",
    "    - Health insurance: 80% employer-paid premium\n",
    "    - 401(k) matching: 6% of salary\n",
    "    - Professional development: $2,000/year\n",
    "    - Gym membership: $50/month reimbursement\n",
    "    - Parental leave: 12 weeks paid for primary caregiver\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"Knowledge base created!\")\n",
    "print(f\"Documents: {list(KNOWLEDGE_BASE.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Document Search Tool\n",
    "\n",
    "Now we'll create a tool that can search this knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSearchTool(BaseTool):\n",
    "    \"\"\"A tool that searches company documents\"\"\"\n",
    "    \n",
    "    name = \"search_documents\"\n",
    "    description = (\n",
    "        \"Searches Acme Corporation's internal documents. \"\n",
    "        \"Input should be a search query or topic (e.g., 'remote work', 'vacation', 'benefits'). \"\n",
    "        \"Returns relevant company policy information.\"\n",
    "    )\n",
    "    \n",
    "    def __init__(self, knowledge_base):\n",
    "        super().__init__()\n",
    "        self.knowledge_base = knowledge_base\n",
    "    \n",
    "    def execute(self, tool_input: str) -> str:\n",
    "        \"\"\"Search for documents matching the query\"\"\"\n",
    "        query = tool_input.lower()\n",
    "        \n",
    "        # Simple keyword matching (real systems use vector similarity)\n",
    "        results = []\n",
    "        for doc_key, doc_content in self.knowledge_base.items():\n",
    "            if query in doc_key or any(word in doc_content.lower() for word in query.split()):\n",
    "                results.append(doc_content)\n",
    "        \n",
    "        if results:\n",
    "            return \"\\n\\n---\\n\\n\".join(results)\n",
    "        else:\n",
    "            return \"No relevant documents found.\"\n",
    "\n",
    "# Create the tool\n",
    "doc_search = DocumentSearchTool(KNOWLEDGE_BASE)\n",
    "print(\"Document search tool created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tool directly\n",
    "result = doc_search.execute(\"remote work\")\n",
    "print(\"Search Results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Grounded Agent\n",
    "\n",
    "Now let's create an agent that can use this tool to provide grounded answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate LLM instance for the agent\n",
    "agent_llm = HuggingFaceAdapter(model_name=\"dolphin3-qwen25-3b\", auth_token=token)\n",
    "\n",
    "# Register the tool\n",
    "tool_registry = ToolRegistry()\n",
    "tool_registry.register(doc_search)\n",
    "\n",
    "# Create executor, memory, and planner\n",
    "executor = ToolExecutor(tool_registry)\n",
    "memory = WorkingMemory()\n",
    "planner = SimpleReActPlanner(agent_llm, tool_registry)\n",
    "\n",
    "# Define the agent's role\n",
    "planner.prompt_builder.role_definition = RoleDefinition(\n",
    "    \"You are Acme Corporation's HR assistant. \"\n",
    "    \"Your job is to answer employee questions about company policies accurately. \"\n",
    "    \"ALWAYS search the company documents before answering - never make up information. \"\n",
    "    \"Use the search_documents tool to find relevant policies, then base your answer on those documents. \"\n",
    "    \"If the information isn't in the documents, say so.\"\n",
    ")\n",
    "\n",
    "# Assemble the agent\n",
    "grounded_agent = SimpleAgent(\n",
    "    llm=agent_llm,\n",
    "    planner=planner,\n",
    "    tool_executor=executor,\n",
    "    memory=memory,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(\"Grounded agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Grounded Agent\n",
    "\n",
    "Let's ask the same question - but now the agent has access to real documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_grounded_agent(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\nAgent thinking...\\n\")\n",
    "    \n",
    "    response = await grounded_agent.arun(question)\n",
    "    \n",
    "    print(f\"\\nAgent Response:\\n{response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Question about remote work\n",
    "await test_grounded_agent(\"What is Acme Corporation's policy on remote work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Question about vacation\n",
    "await test_grounded_agent(\"How many vacation days do employees get after 5 years?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Question about something NOT in the documents\n",
    "await test_grounded_agent(\"What is the dress code policy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection Question 2\n",
    "\n",
    "**What's different between the pure LLM and the grounded agent?**\n",
    "\n",
    "Notice:\n",
    "- The grounded agent searches documents first\n",
    "- Answers are based on actual policy text\n",
    "- When info isn't available, it admits it (no hallucination!)\n",
    "\n",
    "This is **Retrieval-Augmented Generation (RAG)** in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights: Grounding\n",
    "\n",
    "### Without Grounding (Pure LLM):\n",
    "```\n",
    "User: \"What's the remote work policy?\"\n",
    "  ↓\n",
    "LLM: [Predicts based on general patterns]\n",
    "  ↓\n",
    "LLM: \"Most companies allow 2-3 days...\" (HALLUCINATION!)\n",
    "```\n",
    "\n",
    "### With Grounding (RAG Agent):\n",
    "```\n",
    "User: \"What's the remote work policy?\"\n",
    "  ↓\n",
    "Agent: [Searches documents]\n",
    "  ↓\n",
    "Tool: Returns actual policy text\n",
    "  ↓\n",
    "Agent: [Generates answer based on retrieved text]\n",
    "  ↓\n",
    "Agent: \"According to company policy, employees may work remotely up to 3 days per week...\"\n",
    "```\n",
    "\n",
    "**Grounding = Factual, Verifiable, Trustworthy Answers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Committees of AI Agents\n",
    "\n",
    "## Why Use Multiple Agents?\n",
    "\n",
    "Just like human teams, different agents can have different:\n",
    "- **Roles** (specialist vs. generalist)\n",
    "- **Tools** (some agents have access to certain resources)\n",
    "- **Expertise** (some are better at specific tasks)\n",
    "\n",
    "### Real-World Examples:\n",
    "- **Code Review Committee**: One agent writes code, another reviews for bugs, another checks style\n",
    "- **Essay Grading Team**: One checks grammar, another evaluates argument quality, another verifies facts\n",
    "- **Research Team**: One searches papers, another summarizes, another synthesizes findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Essay Evaluation\n",
    "\n",
    "Let's build a committee to grade essays with three specialized agents:\n",
    "1. **Grammar Agent**: Checks spelling, grammar, and clarity\n",
    "2. **Content Agent**: Evaluates argument quality and evidence\n",
    "3. **Coordinator Agent**: Synthesizes feedback and assigns final grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Essay for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_essay = \"\"\"\n",
    "The Impact of Artificial Intelligence on Education\n",
    "\n",
    "Artificial intelligence is revolutionizing education in many ways. AI can personalize learning \n",
    "by adapting to each students pace and style. For example, intelligent tutoring systems can \n",
    "identify where a student struggles and provide targeted practice.\n",
    "\n",
    "However, their are concerns about AI in education. Some worry that students might become to \n",
    "dependent on AI tools and not develop critical thinking skills. Others point out that AI \n",
    "systems can perpetuate biases if there trained on biased data.\n",
    "\n",
    "Despite these challenges, the benefits outweigh the risks. AI can help teachers by automating \n",
    "administrative tasks, allowing them to focus on actual teaching. It can also make education \n",
    "more accessible to students in remote areas who otherwise wouldn't have access to quality \n",
    "instruction.\n",
    "\n",
    "In conclusion, AI has the potential to transform education for the better, but we must \n",
    "implement it thoughtfully and address the ethical concerns. The future of education will \n",
    "likely involve a partnership between human teachers and AI systems, combining the best of both.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample essay loaded!\")\n",
    "print(f\"Length: {len(sample_essay.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Specialized Agent Tools\n",
    "\n",
    "First, let's create tools that represent specialized capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCheckTool(BaseTool):\n",
    "    \"\"\"Tool for checking grammar and writing quality\"\"\"\n",
    "    \n",
    "    name = \"check_grammar\"\n",
    "    description = (\n",
    "        \"Analyzes text for grammar, spelling, and clarity issues. \"\n",
    "        \"Input: essay text. Returns: detailed grammar feedback.\"\n",
    "    )\n",
    "    \n",
    "    def execute(self, tool_input: str) -> str:\n",
    "        \"\"\"Simulate grammar checking\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Simple checks (real systems use NLP libraries)\n",
    "        if \"their are\" in tool_input.lower():\n",
    "            issues.append(\"- Found 'their are' - should be 'there are'\")\n",
    "        if \"to dependent\" in tool_input.lower():\n",
    "            issues.append(\"- Found 'to dependent' - should be 'too dependent'\")\n",
    "        if \"students pace\" in tool_input.lower():\n",
    "            issues.append(\"- Found 'students pace' - missing apostrophe: 'student's pace'\")\n",
    "        if \"there trained\" in tool_input.lower():\n",
    "            issues.append(\"- Found 'there trained' - should be 'they're trained'\")\n",
    "        \n",
    "        if issues:\n",
    "            return \"Grammar Issues Found:\\n\" + \"\\n\".join(issues)\n",
    "        else:\n",
    "            return \"No major grammar issues detected.\"\n",
    "\n",
    "\n",
    "class ContentAnalysisTool(BaseTool):\n",
    "    \"\"\"Tool for analyzing argument quality and evidence\"\"\"\n",
    "    \n",
    "    name = \"analyze_content\"\n",
    "    description = (\n",
    "        \"Evaluates the quality of arguments and evidence in an essay. \"\n",
    "        \"Input: essay text. Returns: content quality assessment.\"\n",
    "    )\n",
    "    \n",
    "    def execute(self, tool_input: str) -> str:\n",
    "        \"\"\"Simulate content analysis\"\"\"\n",
    "        text_lower = tool_input.lower()\n",
    "        \n",
    "        # Count evidence markers\n",
    "        evidence_markers = [\"for example\", \"research shows\", \"studies indicate\", \"data suggests\"]\n",
    "        evidence_count = sum(1 for marker in evidence_markers if marker in text_lower)\n",
    "        \n",
    "        # Check structure\n",
    "        has_intro = \"introduction\" in text_lower or tool_input.startswith(\" \")\n",
    "        has_conclusion = \"conclusion\" in text_lower or \"in summary\" in text_lower\n",
    "        \n",
    "        # Check for counterarguments\n",
    "        has_counterargument = any(word in text_lower for word in [\"however\", \"although\", \"despite\", \"concern\"])\n",
    "        \n",
    "        feedback = \"Content Analysis:\\n\"\n",
    "        feedback += f\"- Evidence examples: {evidence_count}\\n\"\n",
    "        feedback += f\"- Has clear introduction: {has_intro}\\n\"\n",
    "        feedback += f\"- Has conclusion: {has_conclusion}\\n\"\n",
    "        feedback += f\"- Addresses counterarguments: {has_counterargument}\\n\"\n",
    "        \n",
    "        if evidence_count < 2:\n",
    "            feedback += \"\\nSuggestion: Add more specific examples and evidence to support claims.\"\n",
    "        \n",
    "        return feedback\n",
    "\n",
    "\n",
    "# Create the tools\n",
    "grammar_tool = GrammarCheckTool()\n",
    "content_tool = ContentAnalysisTool()\n",
    "\n",
    "print(\"Specialized tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Specialized Agents\n",
    "\n",
    "Now we'll create three agents with different roles and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Grammar Specialist\n",
    "grammar_llm = HuggingFaceAdapter(model_name=\"dolphin3-qwen25-3b\", auth_token=token)\n",
    "grammar_registry = ToolRegistry()\n",
    "grammar_registry.register(grammar_tool)\n",
    "grammar_executor = ToolExecutor(grammar_registry)\n",
    "grammar_memory = WorkingMemory()\n",
    "grammar_planner = SimpleReActPlanner(grammar_llm, grammar_registry)\n",
    "\n",
    "grammar_planner.prompt_builder.role_definition = RoleDefinition(\n",
    "    \"You are a Grammar Specialist. \"\n",
    "    \"Your job is to evaluate the grammar, spelling, and writing clarity of essays. \"\n",
    "    \"Use the check_grammar tool to analyze the text, then provide specific feedback. \"\n",
    "    \"Rate grammar quality on a scale of 1-10 and explain your rating.\"\n",
    ")\n",
    "\n",
    "grammar_agent = SimpleAgent(\n",
    "    llm=grammar_llm,\n",
    "    planner=grammar_planner,\n",
    "    tool_executor=grammar_executor,\n",
    "    memory=grammar_memory,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(\"✓ Grammar Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Content Specialist\n",
    "content_llm = HuggingFaceAdapter(model_name=\"dolphin3-qwen25-3b\", auth_token=token)\n",
    "content_registry = ToolRegistry()\n",
    "content_registry.register(content_tool)\n",
    "content_executor = ToolExecutor(content_registry)\n",
    "content_memory = WorkingMemory()\n",
    "content_planner = SimpleReActPlanner(content_llm, content_registry)\n",
    "\n",
    "content_planner.prompt_builder.role_definition = RoleDefinition(\n",
    "    \"You are a Content Specialist. \"\n",
    "    \"Your job is to evaluate the quality of arguments, evidence, and logical structure in essays. \"\n",
    "    \"Use the analyze_content tool to assess the text, then provide feedback on argument strength. \"\n",
    "    \"Rate content quality on a scale of 1-10 and explain your rating.\"\n",
    ")\n",
    "\n",
    "content_agent = SimpleAgent(\n",
    "    llm=content_llm,\n",
    "    planner=content_planner,\n",
    "    tool_executor=content_executor,\n",
    "    memory=content_memory,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(\"✓ Content Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Coordinator (no special tools, just synthesis)\n",
    "coordinator_llm = HuggingFaceAdapter(model_name=\"dolphin3-qwen25-3b\", auth_token=token)\n",
    "coordinator_registry = ToolRegistry()  # No tools needed\n",
    "coordinator_executor = ToolExecutor(coordinator_registry)\n",
    "coordinator_memory = WorkingMemory()\n",
    "coordinator_planner = SimpleReActPlanner(coordinator_llm, coordinator_registry)\n",
    "\n",
    "coordinator_planner.prompt_builder.role_definition = RoleDefinition(\n",
    "    \"You are the Lead Evaluator and Coordinator. \"\n",
    "    \"Your job is to synthesize feedback from the Grammar and Content specialists. \"\n",
    "    \"Review their assessments, then provide: \"\n",
    "    \"1) An overall grade (A-F) \"\n",
    "    \"2) A summary of strengths \"\n",
    "    \"3) Key areas for improvement \"\n",
    "    \"Be fair but thorough in your evaluation.\"\n",
    ")\n",
    "\n",
    "coordinator_agent = SimpleAgent(\n",
    "    llm=coordinator_llm,\n",
    "    planner=coordinator_planner,\n",
    "    tool_executor=coordinator_executor,\n",
    "    memory=coordinator_memory,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(\"✓ Coordinator Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Committee\n",
    "\n",
    "Now let's coordinate the agents to evaluate our essay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_essay_with_committee(essay_text):\n",
    "    \"\"\"Coordinate multiple agents to evaluate an essay\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ESSAY EVALUATION COMMITTEE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Grammar Agent evaluates\n",
    "    print(\"\\n[GRAMMAR SPECIALIST ANALYZING...]\\n\")\n",
    "    grammar_feedback = await grammar_agent.arun(\n",
    "        f\"Please evaluate the grammar and writing quality of this essay:\\n\\n{essay_text}\"\n",
    "    )\n",
    "    print(f\"Grammar Specialist Report:\\n{grammar_feedback}\")\n",
    "    \n",
    "    # Step 2: Content Agent evaluates\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\n[CONTENT SPECIALIST ANALYZING...]\\n\")\n",
    "    content_feedback = await content_agent.arun(\n",
    "        f\"Please evaluate the content quality and argumentation of this essay:\\n\\n{essay_text}\"\n",
    "    )\n",
    "    print(f\"Content Specialist Report:\\n{content_feedback}\")\n",
    "    \n",
    "    # Step 3: Coordinator synthesizes\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\n[LEAD EVALUATOR SYNTHESIZING...]\\n\")\n",
    "    \n",
    "    coordinator_prompt = f\"\"\"\n",
    "    Please review the following specialist reports and provide a final evaluation:\n",
    "    \n",
    "    GRAMMAR SPECIALIST REPORT:\n",
    "    {grammar_feedback}\n",
    "    \n",
    "    CONTENT SPECIALIST REPORT:\n",
    "    {content_feedback}\n",
    "    \n",
    "    Provide:\n",
    "    1. Overall Grade (A-F)\n",
    "    2. Summary of Strengths\n",
    "    3. Key Areas for Improvement\n",
    "    \"\"\"\n",
    "    \n",
    "    final_evaluation = await coordinator_agent.arun(coordinator_prompt)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(final_evaluation)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    return final_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the committee evaluation!\n",
    "await evaluate_essay_with_committee(sample_essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection Question 3\n",
    "\n",
    "**What advantages does the committee approach have over a single agent?**\n",
    "\n",
    "Think about:\n",
    "- Specialization: Each agent focuses on what it does best\n",
    "- Division of labor: Complex task broken into manageable pieces\n",
    "- Checks and balances: Multiple perspectives reduce bias\n",
    "- Transparency: You can see each agent's reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Multi-Agent Patterns\n",
    "\n",
    "### Common Committee Structures:\n",
    "\n",
    "**1. Sequential Pipeline** (what we just built):\n",
    "```\n",
    "Essay → Grammar Agent → Content Agent → Coordinator → Final Grade\n",
    "```\n",
    "\n",
    "**2. Parallel Processing**:\n",
    "```\n",
    "               ┌─→ Grammar Agent ─┐\n",
    "    Essay ────┤                   ├──→ Coordinator → Result\n",
    "               └─→ Content Agent ─┘\n",
    "```\n",
    "\n",
    "**3. Hierarchical Structure**:\n",
    "```\n",
    "    Manager Agent\n",
    "         |\n",
    "    ┌────┴────┐\n",
    "  Worker 1  Worker 2\n",
    "```\n",
    "\n",
    "**4. Debate/Consensus**:\n",
    "```\n",
    "Agent A ←→ Agent B ←→ Agent C\n",
    "     ↓         ↓         ↓\n",
    "        Consensus Result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "Test the committee on your own essay or writing sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_essay = \"\"\"\n",
    "Paste your essay here!\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment to test:\n",
    "# await evaluate_essay_with_committee(your_essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights: Multi-Agent Systems\n",
    "\n",
    "### Why Committees Beat Single Agents:\n",
    "\n",
    "**Specialization**:\n",
    "- Each agent masters one skill\n",
    "- Like human experts, focused agents perform better\n",
    "\n",
    "**Scalability**:\n",
    "- Add new specialists as needed\n",
    "- Agents can work in parallel for speed\n",
    "\n",
    "**Reliability**:\n",
    "- Multiple perspectives catch more issues\n",
    "- One agent's weakness is another's strength\n",
    "\n",
    "**Transparency**:\n",
    "- See each agent's reasoning\n",
    "- Easier to debug and improve\n",
    "\n",
    "### When to Use Committees:\n",
    "- ✅ Complex tasks requiring multiple skills\n",
    "- ✅ Quality-critical applications (grading, review, analysis)\n",
    "- ✅ Tasks that benefit from different perspectives\n",
    "- ❌ Simple queries (overkill)\n",
    "- ❌ Extremely time-sensitive tasks (coordination adds latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combining Grounding + Committees\n",
    "\n",
    "The most powerful systems combine BOTH techniques:\n",
    "\n",
    "```\n",
    "Research Team Example:\n",
    "\n",
    "Search Agent (grounded on academic papers)\n",
    "     ↓\n",
    "Summarization Agent (processes search results)\n",
    "     ↓\n",
    "Synthesis Agent (combines insights)\n",
    "     ↓\n",
    "Final Report\n",
    "```\n",
    "\n",
    "Each agent is:\n",
    "- **Grounded** (has access to relevant knowledge)\n",
    "- **Specialized** (focuses on one task)\n",
    "- **Coordinated** (works with other agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reflection\n",
    "\n",
    "### 1. How does grounding solve the hallucination problem?\n",
    "### 2. When would you use RAG vs. fine-tuning a model?\n",
    "### 3. What are the tradeoffs between single agents and committees?\n",
    "### 4. Can you think of a real-world task that would benefit from BOTH grounding AND multiple agents?\n",
    "### 5. How might you apply these techniques to your final project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've learned advanced agentic AI techniques:\n",
    "\n",
    "### Grounding Foundation Models:\n",
    "- ✓ Why LLMs hallucinate\n",
    "- ✓ How RAG works\n",
    "- ✓ Building document-grounded agents\n",
    "- ✓ Retrieval → Augmentation → Generation pattern\n",
    "\n",
    "### Multi-Agent Committees:\n",
    "- ✓ Agent specialization and roles\n",
    "- ✓ Coordinating multiple agents\n",
    "- ✓ Sequential and parallel workflows\n",
    "- ✓ Synthesizing diverse feedback\n",
    "\n",
    "### What's Next?\n",
    "- Experiment with different committee structures\n",
    "- Build agents grounded on YOUR data\n",
    "- Combine techniques for your final projects\n",
    "- Explore advanced patterns (debate, voting, hierarchies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Challenges (Optional)\n",
    "\n",
    "If you want to explore further, try these:\n",
    "\n",
    "### Challenge 1: Improve the Knowledge Base\n",
    "Add more documents to the knowledge base and test different search strategies.\n",
    "\n",
    "### Challenge 2: Add More Specialists\n",
    "Create a third specialist agent (e.g., \"Citation Checker\" or \"Originality Detector\").\n",
    "\n",
    "### Challenge 3: Parallel Evaluation\n",
    "Modify the committee to run grammar and content agents in parallel using `asyncio.gather()`.\n",
    "\n",
    "### Challenge 4: Voting System\n",
    "Create multiple grading agents that vote on the final grade rather than having one coordinator.\n",
    "\n",
    "### Challenge 5: Your Own Committee\n",
    "Design a multi-agent system for a task relevant to your final project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
